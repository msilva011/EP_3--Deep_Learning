{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c4018d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import os\n",
    "import shutil, os\n",
    "\n",
    "# api = KaggleApi()\n",
    "# api.authenticate()\n",
    "\n",
    "DATA_DIR   = 'data'\n",
    "TARGET_DIR = 'data/16_animes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b98419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = 'data'\n",
    "# if not os.path.exists(DATA_DIR):\n",
    "#     os.makedirs(DATA_DIR)\n",
    "#     api.dataset_download_files('diraizel/anime-images-dataset', path=DATA_DIR, unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77a47951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10_animes', '16_animes']\n"
     ]
    }
   ],
   "source": [
    "import shutil, os\n",
    "os.makedirs(TARGET_DIR, exist_ok=True)\n",
    "\n",
    "all_animes = sorted(os.listdir(DATA_DIR))\n",
    "print(all_animes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29a20365",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = [\n",
    "    'AKIRA',\n",
    "    'Attack on Titan',\n",
    "    'Cardcaptor Sakura',\n",
    "    'Fullmetal Alchemist Brotherhood',\n",
    "    'Dragon Ball Z',\n",
    "    'Death Note',\n",
    "    'Haikyu!!',\n",
    "    'My Hero Academia',\n",
    "    'Hunter x Hunter',\n",
    "    'Nana',\n",
    "    'Nanatsu no Taizai',\n",
    "    'Naruto',\n",
    "    'Yu Yu Hakusho',\n",
    "    'Your Name',\n",
    "    'Violet Evergarden',\n",
    "    'One Piece',\n",
    "]\n",
    "\n",
    "# os.makedirs(TARGET_DIR, exist_ok=True)\n",
    "\n",
    "# for anime in selected:\n",
    "#     src = os.path.join(DATA_DIR, anime)\n",
    "#     dst = os.path.join(TARGET_DIR, anime)\n",
    "#     shutil.copytree(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e074fe28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)                      \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cf33ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4740 images belonging to 16 classes.\n",
      "Found 1181 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    'data/16_animes',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_gen = train_datagen.flow_from_directory(\n",
    "    'data/16_animes',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
